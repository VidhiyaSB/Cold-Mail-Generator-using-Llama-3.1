{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bfd68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
      "Collecting groq<1,>=0.4.1\n",
      "  Downloading groq-0.10.0-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.3/106.3 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting langchain-core<0.3.0,>=0.2.26\n",
      "  Downloading langchain_core-0.2.37-py3-none-any.whl (396 kB)\n",
      "     -------------------------------------- 396.2/396.2 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<5,>=4.7\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (3.5.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "     -------------------------------------- 423.9/423.9 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-groq) (6.0)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.75\n",
      "  Downloading langsmith-0.1.108-py3-none-any.whl (150 kB)\n",
      "     -------------------------------------- 150.7/150.7 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting packaging<25,>=23.2\n",
      "  Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 54.0/54.0 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.3)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.9/77.9 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2022.9.14)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.7-cp39-none-win_amd64.whl (137 kB)\n",
      "     -------------------------------------- 137.1/137.1 kB 8.5 MB/s eta 0:00:00\n",
      "Collecting pydantic-core==2.20.1\n",
      "  Downloading pydantic_core-2.20.1-cp39-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 4.5 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-groq) (1.26.11)\n",
      "Installing collected packages: typing-extensions, tenacity, packaging, orjson, jsonpointer, h11, distro, annotated-types, pydantic-core, jsonpatch, httpcore, pydantic, httpx, langsmith, groq, langchain-core, langchain-groq\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 groq-0.10.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.37 langchain-groq-0.1.9 langsmith-0.1.108 orjson-3.10.7 packaging-24.1 pydantic-2.8.2 pydantic-core-2.20.1 tenacity-8.5.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1159df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian cricketer.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key = 'apikey',\n",
    "    model_name=\"llama-3.1-70b-versatile\"\n",
    ")\n",
    "response = llm.invoke(\"Virat Kohli is an...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ca75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadbNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "     -------------------------------------- 584.3/584.3 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting numpy<2.0.0,>=1.22.5\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 8.3 MB/s eta 0:00:00\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.3/47.3 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from chromadb) (2.8.2)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Downloading grpcio-1.66.1-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Collecting fastapi>=0.95.2\n",
      "  Downloading fastapi-0.112.2-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.5/93.5 kB ? eta 0:00:00\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
      "     ------------------------------------ 151.7/151.7 kB 137.2 kB/s eta 0:00:00\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 5.7 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-3.6.0-py2.py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.6/50.6 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting overrides>=7.3.1\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from chromadb) (3.10.7)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.4.4-py3-none-any.whl (35 kB)\n",
      "Collecting chroma-hnswlib==0.7.6\n",
      "  Downloading chroma_hnswlib-0.7.6-cp39-cp39-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.1/151.1 kB 9.4 MB/s eta 0:00:00\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-4.1.0-cp39-cp39-win_amd64.whl (31 kB)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Downloading tokenizers-0.20.0-cp39-none-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from chromadb) (8.5.0)\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     -------------------------------------- 67.3/67.3 kB 905.1 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "     -------------------------------------- 110.5/110.5 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 64.0/64.0 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.19.0-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "     ---------------------------------------- 11.1/11.1 MB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from chromadb) (6.0)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.65.0\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.5)\n",
      "Collecting starlette<0.39.0,>=0.37.2\n",
      "  Downloading starlette-0.38.4-py3-none-any.whl (71 kB)\n",
      "     -------------------------------------- 71.4/71.4 kB 657.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2022.9.14)\n",
      "Requirement already satisfied: anyio in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "     -------------------------------------- 200.9/200.9 kB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.28.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.11)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.28.0-cp39-cp39-win_amd64.whl (431 kB)\n",
      "     -------------------------------------- 431.6/431.6 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.10.1)\n",
      "Collecting deprecated>=1.2.6\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting importlib-metadata>=4.6\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "     -------------------------------------- 220.9/220.9 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.27.0\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "     -------------------------------------- 52.5/52.5 kB 681.0 kB/s eta 0:00:00\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.25.4-cp39-cp39-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "     -------------------------------------- 149.7/149.7 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-util-http==0.48b0\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (63.4.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "     -------------------------------------- 417.5/417.5 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.8.0-py3-none-any.whl (241 kB)\n",
      "     -------------------------------------- 241.6/241.6 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-13.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "     -------------------------------------- 152.2/152.2 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp39-cp39-win_amd64.whl (60 kB)\n",
      "     ---------------------------------------- 60.2/60.2 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.24.0-cp39-none-win_amd64.whl (277 kB)\n",
      "     -------------------------------------- 277.8/277.8 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from importlib-resources->chromadb) (3.8.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.6.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "     ------------------------------------- 177.6/177.6 kB 10.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (2.0.4)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 7.6 MB/s eta 0:00:00\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53836 sha256=8957df281bd3d633573139b0b4a8c78e653618bc36fde5027075e668f3bbe391\n",
      "  Stored in directory: c:\\users\\vidhiya s b\\appdata\\local\\pip\\cache\\wheels\\f7\\02\\64\\d541eac67ec459309d1fb19e727f58ecf7ffb4a8bf42d4cfe5\n",
      "Successfully built pypika\n",
      "Installing collected packages: pyreadline3, pypika, monotonic, mmh3, flatbuffers, websockets, tqdm, shellingham, rsa, python-dotenv, pyproject_hooks, pygments, protobuf, overrides, opentelemetry-util-http, oauthlib, numpy, mdurl, importlib-resources, importlib-metadata, humanfriendly, httptools, grpcio, fsspec, deprecated, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, markdown-it-py, huggingface-hub, googleapis-common-protos, google-auth, coloredlogs, chroma-hnswlib, build, tokenizers, rich, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, typer, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Uninstalling importlib-metadata-4.11.3:\n",
      "      Successfully uninstalled importlib-metadata-4.11.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.1 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.112.2 flatbuffers-24.3.25 fsspec-2024.6.1 google-auth-2.34.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 httptools-0.6.1 huggingface-hub-0.24.6 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.4 kubernetes-30.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.19.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.6.0 protobuf-4.25.4 pygments-2.18.0 pypika-0.48.9 pyproject_hooks-1.1.0 pyreadline3-3.4.1 python-dotenv-1.0.1 requests-oauthlib-2.0.0 rich-13.8.0 rsa-4.9 shellingham-1.5.4 starlette-0.38.4 tokenizers-0.20.0 tqdm-4.66.5 typer-0.12.5 uvicorn-0.30.6 watchfiles-0.24.0 websockets-13.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17695fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (0.1.108)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (2.28.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.10.5-cp39-cp39-win_amd64.whl (379 kB)\n",
      "     -------------------------------------- 379.8/379.8 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting langchain<0.3.0,>=0.2.15\n",
      "  Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.37 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.37)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-community) (1.4.39)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.7/50.7 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.7-cp39-cp39-win_amd64.whl (109 kB)\n",
      "     -------------------------------------- 109.5/109.5 kB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "     -------------------------------------- 49.3/49.3 kB 494.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.15->langchain-community) (2.8.2)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.37->langchain-community) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.37->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.15->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\vidhiya s b\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\n",
      "Installing collected packages: typing-inspect, multidict, marshmallow, frozenlist, async-timeout, aiohappyeyeballs, yarl, dataclasses-json, aiosignal, aiohttp, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.4.1 langchain-0.2.15 langchain-community-0.2.15 langchain-text-splitters-0.2.2 marshmallow-3.22.0 multidict-6.0.5 typing-inspect-0.9.0 yarl-1.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e44f6fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply for Lead Data Engineer\n",
      "\n",
      "Search JobsSkip navigationSearch JobsNIKE, INC. JOBSContract JobsJoin The Talent CommunityLife @ NikeOverviewBenefitsBrandsOverviewJordanConverseTeamsOverviewAdministrative SupportAdvanced InnovationAir Manufacturing InnovationAviationCommunicationsCustomer ServiceDesignDigitalFacilitiesFinance & AccountingGovernment & Public AffairsHuman ResourcesInsights & AnalyticsLegalManufacturing & EngineeringMarketingMerchandisingPlanningPrivacyProcurementProduct Creation, Development & ManagementRetail CorporateRetail StoresSalesSocial & Community ImpactSports MarketingStrategic PlanningSupply Chain, Distribution & LogisticsSustainabilityTechnologyLocationsOverviewNike WHQNike New York HQEHQ: Hilversum, The NetherlandsELC: Laakdal, BelgiumGreater China HQDiversity, Equity & InclusionOverviewMilitary InclusionDisability InclusionIndigenous InclusionInternshipsData & AnalyticsLead Data EngineerKarnataka, IndiaBecome a Part of the NIKE, Inc. Team\n",
      "NIKE, Inc. does more than outfit the worldâ€™s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. itâ€™s about each person bringing skills and passion to a challenging and constantly evolving game.WHO ARE WE LOOKING FORWe are looking for a Lead Data  Platform Engineer who excels in team environments and are excited about building cloud native platforms that can scale with the demand of our business. This role is part of Enterprise Architecture and Developer Experience aggressively innovates solutions to drive growth while creating and implementing tools that help make everything else in the company possible. The candidate needs to have a strong understanding of technical concepts, excellent attention to detail, data accuracy, and data analysis, strong verbal and written communication skills, and be self-motivated and operates with a high sense of urgency and a high level of integrity.WHAT WILL YOU WORK ONEvangelize and cultivate adoption of GPaaS, open source software and agile principles within the organizationDeveloping and Implementing Inhouse SolutionsEnsure solutions are designed and developed using a scalable, highly resilient cloud native architectureDeliver well-documented and well-tested code, and participate in peer code reviewsDesign and develop tools and frameworks to improve security, reliability, maintainability, availability and performance for the technology foundation of our platformEnsure product and technical features are delivered to spec and on-timeCollaborate with and consult other Nike development teams, architecture teams etc.Explain designs and constraints to stakeholders and technical teams, gather alignment and buy-inProvide responsive support and operations for the platforms you help build.Work with product management to support product / service scoping activitiesWork with leadership to define delivery schedules of key features through an agile frameworkBe a key contributor to overall architecture, framework and design of GPaaSWHO WILL YOU WORK WITHThis role is part of the Global PaaS and work with Advanced Computing teamWHAT YOU BRING Minimum 8+ years of working experience in designing and building production grade Microservices in any programming languages preferably  in Python Extensive Experience in Big Data Technologies - Databricks, EMRâ€™s and Other Cloud Compute ToolsMust have Experience in AWS web Services (like EC2, RDS, Lambda, S3, LoadBalancer, ECS, EKS etc). Experience Building end to end CI/CD pipeline to build, test and deploy to different AWS environments such as lambda, EC2,ECS , EKS etc.Familiarity with software engineering best practices â€“ including unit tests, code review, version control, production monitoring, etc.Strong Experience on Jenkins, Terraform, Docker, Kubernetes etc.,Strong understanding of OOP Concepts, Data Structures and Design Patterns.Strong understanding of Web Services, Caching, Scalability, REST Principles.Have knowledge of databases like Databricks SQL, Trino, MySQL, Postgresql etc.Good Knowledge of computer science fundamentalsExperience with different services of AWS.Ability to work independently in a fast paced and agile development environment.Keen to explore new technologies.Knowledge of Data GovernanceNIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.How We HireAt NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best â€” and to do that, you need to understand how the hiring process works. Transparency is key.\r\n",
      "\r\n",
      "* This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.Start nowBenefitsWhether itâ€™s transportation or financial health, we continually invest in our employees to help them achieve greatness â€” inside and outside of work. All who work here should be able to realize their full potential.Employee Assistance ProgramHolidaysMedical PlanPaid Time Off (PTO)Product DiscountsLearn moreFIND A STOREBECOME A MEMBERSIGN UP FOR EMAILSEND US FEEDBACKSTUDENT DISCOUNTSGET HELPGET HELPOrder StatusDeliveryReturnsPayment OptionsContact Us On Nike.com InquiriesContact Us On All Other InquiriesABOUT NIKEABOUT NIKENewsCareersInvestorsSustainabilityIndiaÂ© 2024 Nike, Inc. All Rights ReservedGuidesNike AdaptNike Air MaxNike FlyleatherNike PegasusNike Zoom FlyNike AirNike FlyEaseNike FreeNike ReactNike ZoomXNike Air Force 1Nike FlyknitNike JoyrideNike VaporflyTerms of SaleTerms of UseNike Privacy Policy\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://jobs.nike.com/job/R-34832?from=job%20search%20funnel\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358cda3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract  = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e7e94f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Lead Data Engineer',\n",
       " 'experience': 'Minimum 8+ years of working experience in designing and building production grade Microservices',\n",
       " 'skills': ['Python',\n",
       "  'Big Data Technologies - Databricks, EMR’s and Other Cloud Compute Tools',\n",
       "  'AWS web Services (like EC2, RDS, Lambda, S3, LoadBalancer, ECS, EKS etc.)',\n",
       "  'CI/CD pipeline',\n",
       "  'Jenkins',\n",
       "  'Terraform',\n",
       "  'Docker',\n",
       "  'Kubernetes',\n",
       "  'OOP Concepts',\n",
       "  'Data Structures',\n",
       "  'Design Patterns',\n",
       "  'Web Services',\n",
       "  'Caching',\n",
       "  'Scalability',\n",
       "  'REST Principles',\n",
       "  'Databases like Databricks SQL, Trino, MySQL, Postgresql etc.',\n",
       "  'Data Governance'],\n",
       " 'description': 'We are looking for a Lead Data Platform Engineer who excels in team environments and are excited about building cloud native platforms that can scale with the demand of our business. This role is part of Enterprise Architecture and Developer Experience aggressively innovates solutions to drive growth while creating and implementing tools that help make everything else in the company possible.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc091b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b0578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Techstack</th>\n",
       "      <th>Links</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>React, Node.js, MongoDB</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angular,.NET, SQL Server</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python, Django, MySQL</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java, Spring Boot, Oracle</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flutter, Firebase, GraphQL</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WordPress, PHP, MySQL</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Magento, PHP, MySQL</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>React Native, Node.js, MongoDB</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iOS, Swift, Core Data</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Android, Java, Room Persistence</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kotlin, Android, Firebase</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Android TV, Kotlin, Android NDK</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iOS, Swift, ARKit</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cross-platform, Xamarin, Azure</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Backend, Kotlin, Spring Boot</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frontend, TypeScript, Angular</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full-stack, JavaScript, Express.js</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Machine Learning, Python, TensorFlow</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DevOps, Jenkins, Docker</td>\n",
       "      <td>https://drive.google.com/file/d/1ZU2emdHHfHr2g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Techstack  \\\n",
       "0                React, Node.js, MongoDB   \n",
       "1               Angular,.NET, SQL Server   \n",
       "2      Vue.js, Ruby on Rails, PostgreSQL   \n",
       "3                  Python, Django, MySQL   \n",
       "4              Java, Spring Boot, Oracle   \n",
       "5             Flutter, Firebase, GraphQL   \n",
       "6                  WordPress, PHP, MySQL   \n",
       "7                    Magento, PHP, MySQL   \n",
       "8         React Native, Node.js, MongoDB   \n",
       "9                  iOS, Swift, Core Data   \n",
       "10       Android, Java, Room Persistence   \n",
       "11             Kotlin, Android, Firebase   \n",
       "12       Android TV, Kotlin, Android NDK   \n",
       "13                     iOS, Swift, ARKit   \n",
       "14        Cross-platform, Xamarin, Azure   \n",
       "15          Backend, Kotlin, Spring Boot   \n",
       "16         Frontend, TypeScript, Angular   \n",
       "17    Full-stack, JavaScript, Express.js   \n",
       "18  Machine Learning, Python, TensorFlow   \n",
       "19               DevOps, Jenkins, Docker   \n",
       "\n",
       "                                                Links  Unnamed: 2  \n",
       "0   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "1   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "2   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "3   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "4   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "5   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "6   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "7   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "8   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "9   https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "10  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "11  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "12  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "13  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "14  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "15  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "16  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "17  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "18  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  \n",
       "19  https://drive.google.com/file/d/1ZU2emdHHfHr2g...         NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"my_portfolio1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb52cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Techstack\"],\n",
    "                       metadatas={\"links\": row[\"Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd4a59d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}],\n",
       " [{'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'},\n",
       "  {'links': 'https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link'}]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = json_res\n",
    "links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "319a1857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'Big Data Technologies - Databricks, EMR’s and Other Cloud Compute Tools',\n",
       " 'AWS web Services (like EC2, RDS, Lambda, S3, LoadBalancer, ECS, EKS etc.)',\n",
       " 'CI/CD pipeline',\n",
       " 'Jenkins',\n",
       " 'Terraform',\n",
       " 'Docker',\n",
       " 'Kubernetes',\n",
       " 'OOP Concepts',\n",
       " 'Data Structures',\n",
       " 'Design Patterns',\n",
       " 'Web Services',\n",
       " 'Caching',\n",
       " 'Scalability',\n",
       " 'REST Principles',\n",
       " 'Databases like Databricks SQL, Trino, MySQL, Postgresql etc.',\n",
       " 'Data Governance']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "352a621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Lead Data Platform Engineer Position\n",
      "\n",
      "I am excited to express my interest in the Lead Data Platform Engineer role within the Enterprise Architecture and Developer Experience team. With a strong background in designing and implementing scalable cloud-native platforms, I am confident that my skills and experience align with the job requirements.\n",
      "\n",
      "As a seasoned data platform engineer, I have a proven track record of building and leading high-performing teams to deliver innovative solutions that drive business growth. My expertise in cloud computing, data architecture, and software development enables me to effectively collaborate with cross-functional teams to design and implement tools that support business objectives.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to work in a team environment and contribute to the development of cutting-edge solutions that can scale with the demand of the business. I am impressed by the company's commitment to innovation and its focus on creating tools that enable growth and efficiency.\n",
      "\n",
      "I would welcome the opportunity to discuss my application and how my skills and experience align with the job requirements. Please find my resume at https://drive.google.com/file/d/1ZU2emdHHfHr2gPzAbnIME61BhKg1EwfK/view?usp=drive_link, which provides more details about my qualifications and experience.\n",
      "\n",
      "I look forward to the opportunity to contribute to the company's success as a Lead Data Platform Engineer.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# ChromaDB setup (assuming this is already done in your environment)\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "job_application_email_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "### JOB DESCRIPTION:\n",
    "{job_description}\n",
    "\n",
    "### INSTRUCTION:\n",
    "You are a job applicant writing a cold email to the HR department regarding the job described above. Your task is to compose a professional and compelling email that:\n",
    "\n",
    "1. Expresses your interest in the position\n",
    "2. Highlights your relevant skills and experience\n",
    "3. Demonstrates your knowledge of the job requirements\n",
    "4. Includes the following link(s) to your resume or portfolio: {resume_links}\n",
    "\n",
    "Keep the email concise, professional, and tailored to the specific job. Do not provide a preamble or mention any specific names. Do not include any closing phrases like \"Best regards\" or similar. End the email with the last relevant sentence.\n",
    "\n",
    "### EMAIL (NO PREAMBLE, NO CLOSING PHRASE):\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Retrieve job description and skills from json_res\n",
    "job = json_res\n",
    "job_description = job.get('description', '')\n",
    "skills = job.get('skills', [])\n",
    "\n",
    "# Query ChromaDB for relevant resume links\n",
    "query_result = collection.query(query_texts=skills, n_results=2)\n",
    "metadatas = query_result.get('metadatas', [])\n",
    "\n",
    "# Extract links from metadatas\n",
    "resume_links = []\n",
    "for metadata_list in metadatas:\n",
    "    for metadata in metadata_list:\n",
    "        links = metadata.get('links', '')\n",
    "        if links:\n",
    "            resume_links.extend(links.split(','))\n",
    "\n",
    "# Remove duplicates and empty strings\n",
    "resume_links = list(set(link.strip() for link in resume_links if link.strip()))\n",
    "\n",
    "# Create the email chain\n",
    "chain_email = job_application_email_prompt | llm\n",
    "\n",
    "# Generate the email\n",
    "res = chain_email.invoke({\n",
    "    \"job_description\": job_description,\n",
    "    \"resume_links\": \", \".join(resume_links) if resume_links else \"No links available\"\n",
    "})\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fed83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac62fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
